
2025

    - Q3

        -- October 

            --- 29th 

                ---- setup: Linux project/notes space, installed python and jupyter 

                ---- DevOps: Y1-Q1 plan structure created - with month1-week1 detailed target created  
            
            --- 30th

                ---- DevOps: In Progress - venv
                        -> create/activate/deactivate/install packages with 'venv'
                        -> why venv? -> isolation, dependency management, avoid system pollution 
                        -> folder structure of venv, access to standard python library even not included in installation 
                
                ---- completed notes on first-time WSL set up in VS Code 

                ---- other notes 
                        -> system: environment vs. virtual environment 
                        -> systen: binary - machine executable code 
                        -> Spark: compatibility with Windows vs. Linux (WSL)
            
            --- 31th

                ---- skipped - day trip to Saskatoon 
        
        -- Novmber 

            --- week 0

                --- 1st 

                    ---- DevOps: Finished - venv
                            -> execution of isolation and lightweight Python installation through 'pyvenv.cfg' file, modify sys.path, PYTHONPATH, PATH
                            -> customize virtualenv: update core dependencies, include system site-packages
                            -> manage virtualenv: locate venv folder, requirements.txt, avoid in Production 
                    
                    ---- DevOps: week2 plan created - realized adjustment needed - focused on working with virtualevn in Poetry + Conda, determine - is it really needed? 
                    
                    ---- DeepLearning: Y1-Q1 plan structure created - with month1-week1 detailed target created (switched 3 plans - 1 hour)
                
                --- 2nd 

                    ---- DeepLearning: micrograd
                            -> overall idea: construct computational graph, so back propagation can be implemented easily from chain rule
                            -> derivative concepts #1 - numeric comutation 
                            -> constructed basic 'Value' class 
                            -> working on functions to visualize computational graph - learning traversal of nodes 
                
            --- week 1

                --- 3rd

                    ---- DevOps Layer 0: Linux Foundamentals Intro notes refactor 
                            -> linux basics: pwd, cd, ls, file, less
                
                --- 4th

                    ---- DevOps Layer 0: notes refactor + temp: shell scripting
                            -> files and directories: cp, mv, mkdir, rm, ln 
                            -> common commands: type, which, help, man, apropos, whatis, info, alias 
                            -> redirecting: >, >>, 2>, &>, /dev/null, cat - append & stdin, |, sort, uniq, wc, grep, head/tail, tee
                
                --- 5th

                    ---- DevOps Layer 0: notes 
                            -> reorganized redirecting and pipeline & filters (subsequent contents require re-read for deep understanding)
                            -> started expansion 
                    
                    ---- reflection
                            -> The Ones Who Believed First 
                            -> MonetteOS + visibility
                    
                    ---- work
                            -> experimented file transfer between Windows and WSL 
                
                --- 6th

                    ---- DevOps Layer 0 (3)
                            -> expansions: pathname (echo D*), tilde (echo ~), arithmetic (echo $((2+ 2))), brace (echo Number_{1..5}), 
                            -> expansions: command substitution ($(ls) | less), parameter (echo $USER)
                            -> quoting: double quote supresses except $, \, `, single quote supresses everything, '\' - escape one char
                            -> recreated: target file for part 1

                    ---- work 
                            -> initial PL extraction with Spark experiment success! 2 minutes -> 12 seconds
                
                --- 7th

                    ---- DevOps Layer 0 
                            -> keyboard tricks 
                    
                    ---- DevOps Layer 1
                            -> restructured and started learning 
                            -> detailed look at python verion 

                --- 8th 

                    ---- DeepLearning Layer 1
                            -> setup venv for dp-experiments
                            -> started implementing micrograd from scratch
                            -> deep dive - env, python interpreter / package change with 'cd' directories
                    
                    ---- mindware
                            -> cognition
                                --> learning 
                                    ---> passive familiarity -> active competence (extremely fast progress compared to regular learner)
                                    ---> apprentice (replicating code with reference) -> engineer-research mindset
                                --> processional
                                    ---> vs. NetSuite 
                                    ---> my system = Monette OS - from COO 
                                    ---> what I have accomplished? 
                                    ---> broad qualities learnt 
                                    ---> future job-seek implication 
                                    ---> department vision proposal - 2025-11-05
                                    ---> inter-dimensional growth 
                                    ---> risk (uncertainty) & reward 
                            -> growth 
                                --> tech growth 
                                    ---> thinking pattern for mastery 
                                    ---> don't try to understand everything 
                            -> observation 
                                --> vs. other people 
                                    ---> (social) default social script: "get job -> go out -> complain about job -> repeat"
                                    ---> living in a different world
                
                --- 9 th 

                    ---- mindware (4.5 h)

            --- week 2

                --- 10th 

                    ---- DevOps: L0 - moving through processes - realized need learning with observing processes as terminal froze

                    ---- Deep Learning
                            -> deep dive into convolutional layer computation 
                            -> re-planned learning plan - deep learning book (theoretical understanding) - dive into deep learning (reference for practicing coding)
                
                --- 11th

                    ---- DevOps: L0 - proceses 
                            -> viewing processes 
                            -> putting process to background and view them 
                            -> signal through 'kill', shut down system, finished process 
                    
                    ---- DeepLearning: L0 - linear algebra
                            -> diagnosed what's missing in the learning process - defined how to learn 
                
                --- 12th

                    ---- DevOps: L0 - environment 
                            -> what is stored in environment, how is environment established 
                    
                    ---- work 
                            -> finished manual configuring task/partition/cores with 'mapPartitions' & 'foreachPartition' for Spark - built-in after this point 
                
                --- 13th

                    ---- DevOps: L0 - environment 
                            -> understood deeply about login shell and non-login shell (which startup files for establishing environment)
                            -> how is environment established through startup files + text editor for customizing those files 
                
                    ---- work 
                            -> understood deeply about repartition, and write afterwards - repartition forces one key to be in the same partition always 
                
                



























