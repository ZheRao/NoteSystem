
Year 1 - DevOps - Solidifying Software Engineering Fundamentals

    - goal
        -- establish a strong foundation in software development best practices - from version control to basic project structure to testing and environment management 
        -- this year is about moving from "code that works" to clean, maintainable code that can be collaboratively developed and easily deployed 
    
    - additional topics 

    - Q1 - Environments, Packaging & CLI Proficiency 

        -- importance: critical foundation for everything I'll do next: reproducible pipelines, Docker images, Spark jobs, and CI/CD automation

        -- month 1 - Python environments, dependency management, reproducibility 

            --- outcome: you can create, freeze, and recreate isolated dev environments and control versions across systems

            --- week 1 - Foundations 

                ---- read: Real Python: Virtual Environment Primer -
                        -> https://realpython.com/python-virtual-environments-a-primer/
                
                ---- learn: what are 
                        -> environments, 
                        -> PATH, 
                        -> dependency isolation, 
                        -> 'sys.path', 
                        -> site-packages

                ---- practice 
                        -> create venvs via 'venv' and 'conda create'
                        -> install specific versions ('pip install pandas==2.2.3')
                        -> export 'requirements.txt' / 'environment.yml' 
            
            --- week 2 - advanced environment management 

                ---- goal 
                        -> understand how modern Python packaging works (pyproject.toml, wheels, builds)
                        -> know how Poetry compares with Conda and venv 
                        -> be able to initialize, lock, and build a Poetry project cleanly 
                        -> know how to manage dependencies across environments (dev/prod/test)
                        -> understand how this links into Docker and CI/CD 
                
                ---- core concepts 
                        -> understanding Python Packaging Evolution 
                            --> read 
                                ---> https://realpython.com/python-application-layouts/
                                ---> https://packaging.python.org/en/latest/tutorials/packaging-projects/
                            --> learn 
                                ---> what 'setup.py', 'requirements.txt', and 'pyproject.toml' each do 
                                ---> how PEP 517/518 standardized 'pyproject.toml'
                                ---> difference between "application" vs. "library" packaging 
                            --> exercise
                                ---> create a dummy 'hello_pkg/' folder with:
                                        hello_pkg/
                                            pyproject.toml
                                            hello_pkg/
                                                __init__.py
                                                main.py
                                    and manually edit the TOML fields (name, version, dependencies)
                
                ---- Poetry foundations 
                        -> install Poetry & inspect behavior 
                            --> https://python-poetry.org/docs/
                            --> https://realpython.com/dependency-management-python-poetry/
                        -> hands-on practice 
                            --> create a project 
                                poetry new mf_qbo_etl
                                cd mf_qbo_etl
                                poetry add requests polars
                                poetry install
                            --> study 
                                ---> how Poetry builds '.venv' internally
                                ---> meaning of 'project.toml' sections
                                        [tool.poetry]
                                        [tool.poetry.dependencies]
                                        [tool.poetry.dev-dependencies]
                                        [build-system]
                                    add scripts:
                                        [tool.poetry.scripts]
                                        etl-run = "mf_qbo_etl.main:run"
                            --> mini-project 
                                ---> recreate ETL repo (simplified) using Poetry 
                                    ----> moving existing code into a Petry project 
                                    ----> define dev deps ('pytest', 'black', 'isort')
                                    ----> lock versions ('poetry lock')
                                    ----> build a wheel: 'poetry build'
                                    ----> test installing it elsewhere 'pip install dist/mf_qbo_etl-0.1.0-py3-none-any.whl'
                                ---> outcome: rebuild entire ETL environment from scratch with one 'poetry install'

                ---- Conda vs. Poetry vs venv 
                        -> conceptual comparison 
                            --> read 
                                ---> https://realpython.com/python-virtual-environments-a-primer/#poetry-and-conda
                                ---> https://towardsdatascience.com/conda-vs-poetry-what-you-need-to-know-2022-edition-5e59b24a30f6
                            --> learn 
                                ---> 'venv' is Python-native, lightweight
                                ---> 'Conda' manages binaries (C/C++, CUDA) - critical for ML/DL
                                ---> 'Poetry' handles packaging, dependency resolution, and version pinning 

                ---- (Docker) integration with Docker and reproducibility 
                        -> read 
                            --> https://docs.docker.com/build/building/multi-stage/python/
                        -> learn how to 
                            --> copy only 'pyproject.toml' + 'poetry.lock' first --> leverage Docker layer caching
                            --> build reproducible images 
                                FROM python:3.11-slim
                                WORKDIR /app
                                COPY pyproject.toml poetry.lock ./
                                RUN pip install poetry && poetry install --no-root --no-dev
                                COPY . .
                                CMD ["poetry", "run", "python", "main.py"]
                        -> this is the bridge between Week 2 and upcoming Week 3 (reproducibility & configs)
                
                ---- advanced references 
                        -> https://peps.python.org/pep-0621/
                        -> https://peps.python.org/pep-0518/
                        -> https://packaging.python.org/en/latest/specifications/
                


        -- month 2 - packaging & distribution (setup.py / pyproject.toml / wheels / entry-points)

            --- outcome: you can package your code as an installable library or CLI tool (pip install .) and understand modern packaging standards (PEP 517/518)
        
        -- month 3 - Linux + CLI mastery & Bash automation 

            --- outcome: you can navigate Linux confidently, automate tasks, and deploy/test your packaged project on a clean machine (or Docker)

        -- Q1-end checkpoints 

            --- have a packaged project 
                ---- deployable on a different machine (or Docker container) by installing it and running its command-line entry point successfully

            --- able to navigate and operate in a Linux environment 
                ---- can write and run a Bash script for a basic task (e.g., a script that pings a server or processes a log file)
            
            --- aim to complete a Linux CLI challenge or use a site like OverTheWire to test Bash skills


Year 1 - DeepLearning - Foundation: Build Mathematical & Experimental Intuition 

    - goal 
        -- rebuild your neural network understanding from first principles, now with modern engineering rigor 
        -- this year is about mastering the basics throughly - not just knowing what a neural network is, but being able to implement and experiment with them at a low level 

    - additional topics 

        -- PyTorch Internals
            --- why: open the hood a bit - enough to see how the engine breathes, for training custom models 
            --- areas:
                ---- autograd engine fundamentals
                        -> how 'requires_grad', 'backward()', '.detach()' work 
                        ->retain_graph, in-place ops, memory freeing 

    - Q1 - Re-Foundations of Deep Learning (Autograd & Backprop from Scratch)

        -- goal 
            --- focus on fundamental mechanics of neural networks 
            --- ensure you understand automatic differentiation and backpropagation at a granular level 
            --- learn how frameworks like PyTroch perform autograd by building a computational graph and applying the chain rule in reverse to compute gradients 
            --- revisit how weights are initialized and why initialization matters for training stability 

        -- month 1 - The Mathematical Core

            --- outcome: derive and code gradients by hand; focus on understanding and deriving the chain rule for NN 

            --- week 1 - computational graphs & the chain rule 

                ---- study
                        -> study Karpathy's video (into and backprop): https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2
                        -> read 
                            --> CS231n Backprop Notes at https://cs231n.github.io/optimization-2/ 
                            --> 3Blue1Brown: Neural Networks — The Backpropagation Algorithm
                        -> read (light): Deep Learning Book, Ch. 6.5 Back-propagation and Other Differentiation Algorithms

                ---- practice 
                        -> write out by hand a computational graph for a simple function, e.g., f(x,y)=(x+y)∗y, compute ∂f/∂x and ∂f/∂y step by step
                        -> implement a minimal scalar reverse-mode autodiff engine (like micrograd, 50 lines)

        -- month 2 - Build a mini Autograd Engine 

            --- outcome: implement micrograd-style computational graph 
        
        -- month 3 - Build & Train a 3-layer MLP with Only Tensors 

            --- outcome: verify gradients vs PyTorch autograd 









