


Linux environment

    - Ubuntu - start from scratch

        -- start from /home/user 

        -- 'mkdir projects && cd projects' - now inside /home/user/projects 

        -- 'code .' - launch VS Code inside projects folder 
        
    - VS Code - setup WSL env and install necessary packages including python

        -- one-time WSL setup (global tools only)

            --- 'sudo apt update && sudo apt upgrade -y'
                
                ---- keep Ubuntu tidy by updating package list, then upgrade everything that has updates 

                ---- command breakdown 
                        -> 'sudo': run with administrator privileges (needed to change system packages)
                        -> 'apt update': refreshes the local package index from your configured repositories; it doesn't install anything, just learns what the latest versions are 
                        -> 'apt upgrade -y': downloads and installs newer versions of all currently installed packages that have safe upgrades available; '-y' auto-answers "yes"
                
                ---- benefits
                        -> get the latest security patches and bug fixes promptly 
                        -> installed packages stay consistent with repo versions, reducing dependency conflicts
                        -> clears up "stale index" issues (e.g., 404s when repos change) by refreshing metadata first 
                
                ---- further improvements
                        -> doesn't remove unused packages, to clean leftovers: 'sudo apt autoremove' (and optionally 'sudo apt autoclean')
                        -> 'apt upgrade' won't remove packages; if a dependency change requires removals, use 'sudo apt full-upgrade' (more aggressive)
            
            --- 'sudo apt install -y build-essential curl git pkg-config'

                ---- essentials for building python wheels, talking to git, etc. 

                ---- packages 
                        -> build-essential: a meta-package that pulls in GCC/G++ compilers, 'make', and basic headers/tools needed to compile C/C++ extensions
                        -> curl: command-line HTTP client (download files, hit APIs, fetch install scripts)
                        -> git: version control CLI 
                        -> pkg-config: helper that tells compilers where to find headers/libs for dependencies (e.g., '--cflags', '--libs' for 'libssl', 'libxml2', etc.)
                
                ---- "wheels" in Python 
                        -> a wheel ('.whl') is Python's standard built distribution format (PEP 427)
                        -> think of it as a prebuilt, ready-to-install package; when run 'pip install <package>', pip prefers a wheel because it can just unpack files - no compiling
                        -> if a wheel isn't available for your platform/Python version, pip falls back to a source distribution ('sdist', usually a '.tar.gz')
                            and will try to build a wheel locally; that's when you need compilers and headers - hence 'build-essential' and 'pkg-config'
                
                ---- common add-ons when needed (when something fails)
                        -> Python headers: 'sudo apt install -y python3-dev'
                        -> SSL/cryptography: 'sudo apt install -y libssl-dev libffi-dev'
                        -> compression/CSV/Parquet/etc: 'sudo apt install -y zlib1g-dev libbz2-dev liblzma-dev'
                        -> XML: 'sudo apt install -y libxml2-dev libxslt1-dev'
            
            --- 'sudo pat install -y python3 python3-nenv python3-pip'

                ---- packages 
                        -> 'python3': installs Ubuntu's system Python interpreter (usually /usr/bin/python3)
                        -> 'python3-venv': lets you create virtual environment with 'python3 -m venv'
                        -> 'python3-pip': installs pip, Python's package manager 
                
                ---- purpose 
                        -> Ubuntu already uses Python internally (for system tools, package managers, etc.) and that's called the system python 
                            --> if lives under /usr/bin/python3 and is managed by 'apt', not by 'pip'
                        -> it's fine to use this system Python just to bootstrap - that is, to create isolated environments (venv) and install 'pip'
                        -> you should not install your project libraries (like 'pandas', 'torch', etc.) directly into the system python
                            --> after initialization, all real work happens inside the virtual environments, not the system install 
                
                ---- danger of not isolation
                        -> if you 'pip install' or 'pip uninstall' into /usr/lib/python3/dist-packages, you can break the OS 
                        -> it mixes system and user dependencies - hard to maintain 
                            --> you'll lose control over versions when Ubuntu updates packages 

            --- 'sudo apt install -y pipx' and then 'pipx ensurepath' and then (after reboot) 'pipx install jupyterlab'

                ---- sets up pipx, a tool for installing Python CLI apps in their own isolated virtual environments - great for "global" tools like Jupyter - without polluting system Python or Conda envs 

                ---- first command - installs the 'pipx' launcher from Ubuntu repos 

                ---- second command - adds pipx's binary directory (typically ~/.local/bin) to your PATH (by updating your shell rc files)
                        -> after this, newly installed pipx apps are runnable by name 
                
                ---- how pipx works 
                        -> when you run 'pipx install <app>', pipx 
                            --> create a dedicated venv under ~/.local/pipx/venvs/<app>/
                            --> installs the app there 
                            --> symlinks the app's console scripts into ~/.local/bin/
                        -> your Python libraries for projects should still live in your project envs (Conda/venv); use pipx only for standalone command-line tools
                
                ---- 'pip install' vs. 'pipx install'
                        -> 'pip install' installs into the currently active Python environment (your Conda env, venv, or - dangerously - system Python) 
                            --> new package will share that env's packages 
                        -> 'pipx install jupyterlab' creates a dedicated isolated venv just for the new package and exposes 'jupyter-lab' command on your PATH 
                            --> your project packages live elsewhere; Jupyter is just the "app shell"

    - virtual environment 


git

    - create/activate SSH keys for GitHub

    - one-time global setup  




Spark setup 
























